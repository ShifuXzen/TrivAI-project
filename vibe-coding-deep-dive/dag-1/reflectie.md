# Wat is een LLM?

* Een LLM (Large Language Model) is een AI die getraind is op grote hoeveelheden data door middel van een algoritme (artikelen, boeken, videos, etc.). Hierdoor kan het data interpreteren, genereren en manipuleren. Ook kan een LLM van feedback leren en zich doorontwikkelen. Dankzij dit zijn LLM's erg effectief als virtuele assistenten, chatbots, het genereren van tekst en het samenvatten van data.

* Een LLM werkt in de kern door tokens te voorspellen op basis van patronen in taal. Daardoor kan het vloeiende antwoorden geven, code uitleggen, ideeen brainstormen en informatie structureren. Tegelijk zijn er beperkingen: het model kan fouten maken, soms overtuigend klinken terwijl de inhoud onjuist is, en het kan gevoelig zijn voor de manier waarop je de vraag stelt. Ook speelt bias een rol, omdat het model leert van bestaande tekst op het internet.

# Wat zijn de risico's voor developers?

* Een LLM kan fouten maken of dingen verzinnen die overtuigend klinken. Als je dat niet controleert, bouw je op verkeerde informatie.

* De gegenereerde code kan onveilig of slecht onderhoudbaar zijn. Bijvoorbeeld geen input-validatie, waardoor er security problemen ontstaan.

* Er is kans op privacy- of datalekken als je gevoelige informatie in een prompt zet, zoals klantgegevens of API-keys.

* AI kan code opleveren die lijkt op bestaande code met een licentie. Dat kan juridische problemen geven als je het klakkeloos overneemt.

* Je kunt te afhankelijk worden van AI. Dan leer je minder zelf en wordt het lastiger om bugs echt te begrijpen en op te lossen.

* Daarom is het belangrijk om kritisch te blijven, resultaten te verifieren en duidelijke prompts te schrijven. Zie AI als hulpmiddel, niet als autoriteit.
